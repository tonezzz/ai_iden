{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6MPjfT5NrKQ"
      },
      "source": [
        "<div align=\"center\">\n",
        "\n",
        "  <a href=\"https://ultralytics.com/yolo\" target=\"_blank\">\n",
        "    <img width=\"1024\", src=\"https://raw.githubusercontent.com/ultralytics/assets/main/yolov8/banner-yolov8.png\"></a>\n",
        "\n",
        "  [‰∏≠Êñá](https://docs.ultralytics.com/zh/) | [ÌïúÍµ≠Ïñ¥](https://docs.ultralytics.com/ko/) | [Êó•Êú¨Ë™û](https://docs.ultralytics.com/ja/) | [–†—É—Å—Å–∫–∏–π](https://docs.ultralytics.com/ru/) | [Deutsch](https://docs.ultralytics.com/de/) | [Fran√ßais](https://docs.ultralytics.com/fr/) | [Espa√±ol](https://docs.ultralytics.com/es/) | [Portugu√™s](https://docs.ultralytics.com/pt/) | [T√ºrk√ße](https://docs.ultralytics.com/tr/) | [Ti·∫øng Vi·ªát](https://docs.ultralytics.com/vi/) | [ÿßŸÑÿπÿ±ÿ®Ÿäÿ©](https://docs.ultralytics.com/ar/)\n",
        "\n",
        "  <a href=\"https://github.com/ultralytics/ultralytics/actions/workflows/ci.yml\"><img src=\"https://github.com/ultralytics/ultralytics/actions/workflows/ci.yml/badge.svg\" alt=\"Ultralytics CI\"></a>\n",
        "  <a href=\"https://colab.research.google.com/github/ultralytics/notebooks/blob/main/notebooks/how-to-train-ultralytics-yolo-on-carparts-segmentation-dataset.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"></a>\n",
        "\n",
        "\n",
        "  <a href=\"https://ultralytics.com/discord\"><img alt=\"Discord\" src=\"https://img.shields.io/discord/1089800235347353640?logo=discord&logoColor=white&label=Discord&color=blue\"></a>\n",
        "  <a href=\"https://community.ultralytics.com\"><img alt=\"Ultralytics Forums\" src=\"https://img.shields.io/discourse/users?server=https%3A%2F%2Fcommunity.ultralytics.com&logo=discourse&label=Forums&color=blue\"></a>\n",
        "  <a href=\"https://reddit.com/r/ultralytics\"><img alt=\"Ultralytics Reddit\" src=\"https://img.shields.io/reddit/subreddit-subscribers/ultralytics?style=flat&logo=reddit&logoColor=white&label=Reddit&color=blue\"></a>\n",
        "  \n",
        "  Welcome to the Carparts segmentation using Ultralytics YOLO11 üöÄ notebook! <a href=\"https://github.com/ultralytics/ultralytics\">YOLO11</a> is the latest version of the YOLO (You Only Look Once) AI models developed by <a href=\"https://ultralytics.com\">Ultralytics</a>. We hope that the resources in this notebook will help you get the most out of YOLO11. Please browse the YOLO11 <a href=\"https://docs.ultralytics.com/\">Docs</a> for details, raise an issue on <a href=\"https://github.com/ultralytics/ultralytics\">GitHub</a> for support, and join our <a href=\"https://ultralytics.com/discord\">Discord</a> community for questions and discussions!</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Carparts Segmentation using Ultralytics YOLO11\n",
        "\n",
        "This notebook serves as a starting point for training the YOLO11 model on [carparts](https://docs.ultralytics.com/datasets/segment/carparts-seg/) segmentation dataset."
      ],
      "metadata": {
        "id": "7EM2nwU4jshF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset Structure\n",
        "\n",
        "The data distribution within the Carparts Segmentation Dataset is organized as outlined below:\n",
        "\n",
        "- **Training set**: Includes 3156 images, each accompanied by its corresponding annotations.\n",
        "- **Testing set**: Comprises 276 images, with each one paired with its respective annotations.\n",
        "- **Validation set**: Consists of 401 images, each having corresponding annotations."
      ],
      "metadata": {
        "id": "xypoYW_oYZAf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Applications\n",
        "\n",
        "Carparts Segmentation finds applications in automotive quality control, auto repair, e-commerce cataloging, traffic monitoring, autonomous vehicles, insurance processing, recycling, and smart city initiatives. It streamlines processes by accurately identifying and categorizing different vehicle components, contributing to efficiency and automation in various industries."
      ],
      "metadata": {
        "id": "R4SICbq5Yalg"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mGmQbAO5pQb"
      },
      "source": [
        "## Setup\n",
        "\n",
        "pip install `ultralytics` and [dependencies](https://github.com/ultralytics/ultralytics/blob/main/pyproject.toml) and check software and hardware.\n",
        "\n",
        "[![PyPI - Version](https://img.shields.io/pypi/v/ultralytics?logo=pypi&logoColor=white)](https://pypi.org/project/ultralytics/) [![Downloads](https://static.pepy.tech/badge/ultralytics)](https://www.pepy.tech/projects/ultralytics) [![PyPI - Python Version](https://img.shields.io/pypi/pyversions/ultralytics?logo=python&logoColor=gold)](https://pypi.org/project/ultralytics/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbvMlHd_QwMG",
        "outputId": "d79319e3-7151-45bb-d26c-2abecd748313",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install ultralytics\n",
        "import ultralytics\n",
        "ultralytics.checks()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.120 üöÄ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Setup complete ‚úÖ (2 CPUs, 12.7 GB RAM, 41.1/112.6 GB disk)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset YAML File\n",
        "\n",
        "A YAML (Yet Another Markup Language) file defines the dataset configuration, including paths, classes, and other pertinent details. üòÄ"
      ],
      "metadata": {
        "id": "xE6ntKojSfSD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```yaml\n",
        "# Ultralytics YOLO üöÄ, AGPL-3.0 license\n",
        "# Carparts-seg dataset by Ultralytics\n",
        "# Documentation: https://docs.ultralytics.com/datasets/segment/carparts-seg/\n",
        "# Example usage: yolo train data=carparts-seg.yaml\n",
        "# parent\n",
        "# ‚îú‚îÄ‚îÄ ultralytics\n",
        "# ‚îî‚îÄ‚îÄ datasets\n",
        "#     ‚îî‚îÄ‚îÄ carparts-seg  ‚Üê downloads here (132 MB)\n",
        "\n",
        "# Train/val/test sets as 1) dir: path/to/imgs, 2) file: path/to/imgs.txt, or 3) list: [path/to/imgs1, path/to/imgs2, ..]\n",
        "path: ../datasets/carparts-seg # dataset root dir\n",
        "train: train/images # train images (relative to 'path') 3516 images\n",
        "val: valid/images # val images (relative to 'path') 276 images\n",
        "test: test/images # test images (relative to 'path') 401 images\n",
        "\n",
        "# Classes\n",
        "names:\n",
        "  0: back_bumper\n",
        "  1: back_door\n",
        "  2: back_glass\n",
        "  3: back_left_door\n",
        "  4: back_left_light\n",
        "  5: back_light\n",
        "  6: back_right_door\n",
        "  7: back_right_light\n",
        "  8: front_bumper\n",
        "  9: front_door\n",
        "  10: front_glass\n",
        "  11: front_left_door\n",
        "  12: front_left_light\n",
        "  13: front_light\n",
        "  14: front_right_door\n",
        "  15: front_right_light\n",
        "  16: hood\n",
        "  17: left_mirror\n",
        "  18: object\n",
        "  19: right_mirror\n",
        "  20: tailgate\n",
        "  21: trunk\n",
        "  22: wheel\n",
        "\n",
        "# Download script/URL (optional)\n",
        "download: https://github.com/ultralytics/assets/releases/download/v0.0.0/carparts-seg.zip\n",
        "```"
      ],
      "metadata": {
        "id": "h8go3HNgN0WU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train\n",
        "\n",
        "Train YOLO11 on [Detect](https://docs.ultralytics.com/tasks/detect/), [Segment](https://docs.ultralytics.com/tasks/segment/), [Classify](https://docs.ultralytics.com/tasks/classify/) and [Pose](https://docs.ultralytics.com/tasks/pose/) datasets. See [YOLO11 Train Docs](https://docs.ultralytics.com/modes/train/) for more information."
      ],
      "metadata": {
        "id": "fMV-sNfiSt_X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load a model\n",
        "model = YOLO(\"yolo11n-seg.pt\")  # load a pretrained model (recommended for training)\n",
        "\n",
        "# Train the model\n",
        "results = model.train(data=\"carparts-seg.yaml\", epochs=10, imgsz=640, batch=32, workers=64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QUgMYUvlNLvy",
        "outputId": "16b11f79-ae95-404b-c9f7-0037ac01aeed"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n-seg.pt to 'yolo11n-seg.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5.90M/5.90M [00:00<00:00, 147MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.120 üöÄ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=yolo11n-seg.pt, data=carparts-seg.yaml, epochs=10, time=None, patience=100, batch=32, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=64, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, cutmix=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
            "\n",
            "WARNING ‚ö†Ô∏è Dataset 'carparts-seg.yaml' images not found, missing path '/content/datasets/carparts-seg/valid/images'\n",
            "Downloading https://ultralytics.com/assets/carparts-seg.zip to '/content/datasets/carparts-seg.zip'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 133M/133M [00:01<00:00, 87.7MB/s]\n",
            "Unzipping /content/datasets/carparts-seg.zip to /content/datasets/carparts-seg...: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7671/7671 [00:03<00:00, 2225.91file/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset download success ‚úÖ (6.1s), saved to \u001b[1m/content/datasets\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 755k/755k [00:00<00:00, 28.5MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overriding model.yaml nc=80 with nc=23\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
            "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
            "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
            " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
            " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
            " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
            " 23        [16, 19, 22]  1    687925  ultralytics.nn.modules.head.Segment          [23, 32, 64, [64, 128, 256]]  \n",
            "YOLO11n-seg summary: 203 layers, 2,847,093 parameters, 2,847,077 gradients, 10.4 GFLOPs\n",
            "\n",
            "Transferred 510/561 items from pretrained weights\n",
            "Freezing layer 'model.23.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5.35M/5.35M [00:00<00:00, 148MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1342.6¬±537.2 MB/s, size: 35.6 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/carparts-seg/train/labels... 3156 images, 116 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3156/3156 [00:01<00:00, 1690.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/datasets/carparts-seg/train/labels.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 822.5¬±532.0 MB/s, size: 39.3 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/carparts-seg/valid/labels... 401 images, 12 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 401/401 [00:00<00:00, 754.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/datasets/carparts-seg/valid/labels.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to runs/segment/train/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.00037, momentum=0.9) with parameter groups 90 weight(decay=0.0), 101 weight(decay=0.0005), 100 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/10      5.68G      1.324      2.777      4.072      1.478        111        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 99/99 [01:10<00:00,  1.41it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:06<00:00,  1.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        401       2042      0.836     0.0868      0.139      0.101      0.835     0.0863       0.14     0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       2/10      6.89G      1.062       1.91      2.479      1.227        107        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 99/99 [01:02<00:00,  1.57it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:05<00:00,  1.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        401       2042      0.552      0.417      0.336      0.248      0.555      0.422      0.341      0.237\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       3/10      6.92G     0.9416      1.653      1.655      1.136         86        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 99/99 [01:02<00:00,  1.58it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:05<00:00,  1.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        401       2042       0.55      0.517      0.469       0.34      0.558      0.519      0.469      0.319\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       4/10      6.93G     0.8742      1.523      1.379      1.092        102        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 99/99 [01:03<00:00,  1.56it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:05<00:00,  1.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        401       2042      0.491      0.562        0.5      0.383      0.504       0.56      0.506      0.369\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       5/10      6.95G     0.8198      1.406      1.217      1.051        103        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 99/99 [01:03<00:00,  1.57it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:05<00:00,  1.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        401       2042      0.589      0.693      0.614      0.478      0.608      0.675      0.623      0.453\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       6/10      6.96G     0.7749      1.317        1.1      1.031        111        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 99/99 [01:02<00:00,  1.57it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:05<00:00,  1.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        401       2042      0.526      0.735       0.61      0.484      0.528      0.733      0.618      0.468\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       7/10      6.98G     0.7433      1.248      1.019      1.003         83        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 99/99 [01:02<00:00,  1.58it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:05<00:00,  1.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        401       2042       0.59      0.752       0.65      0.517      0.594      0.784      0.667      0.498\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       8/10      6.99G     0.7101      1.197     0.9504     0.9874         94        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 99/99 [01:02<00:00,  1.58it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:05<00:00,  1.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        401       2042      0.578      0.793      0.661      0.535      0.579      0.794      0.671      0.516\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       9/10      7.02G     0.6796       1.14     0.9023     0.9674        121        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 99/99 [01:02<00:00,  1.58it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:05<00:00,  1.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        401       2042      0.573      0.745      0.639      0.518      0.578      0.751      0.647      0.496\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      10/10      7.02G     0.6494      1.094     0.8566     0.9594         88        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 99/99 [01:02<00:00,  1.58it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:05<00:00,  1.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        401       2042      0.588      0.793      0.674      0.553      0.591      0.808      0.689      0.526\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "10 epochs completed in 0.194 hours.\n",
            "Optimizer stripped from runs/segment/train/weights/last.pt, 6.0MB\n",
            "Optimizer stripped from runs/segment/train/weights/best.pt, 6.0MB\n",
            "\n",
            "Validating runs/segment/train/weights/best.pt...\n",
            "Ultralytics 8.3.120 üöÄ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "YOLO11n-seg summary (fused): 113 layers, 2,839,053 parameters, 0 gradients, 10.2 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95):   0%|          | 0/7 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95):  14%|‚ñà‚ñç        | 1/7 [00:01<00:06,  1.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95):  29%|‚ñà‚ñà‚ñä       | 2/7 [00:03<00:09,  1.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:18<00:00,  2.68s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        401       2042      0.588      0.794      0.674      0.553      0.592      0.801      0.689      0.526\n",
            "           back_bumper         94         94      0.829       0.98       0.93      0.754      0.829      0.982      0.929      0.706\n",
            "             back_door        158        159      0.758      0.928      0.908      0.784      0.759      0.931      0.911      0.752\n",
            "            back_glass        114        115      0.877      0.929      0.935      0.807      0.877       0.93      0.935      0.774\n",
            "        back_left_door         15         15      0.522        0.8       0.51      0.438       0.52        0.8       0.51      0.366\n",
            "       back_left_light         19         19      0.452      0.684      0.482      0.368      0.483      0.737      0.573      0.394\n",
            "            back_light        161        226      0.828      0.828      0.832      0.618      0.833      0.841      0.843      0.592\n",
            "       back_right_door         12         12       0.45      0.833      0.709      0.583      0.448      0.833      0.709      0.514\n",
            "      back_right_light         13         13      0.415      0.846      0.459      0.388      0.412      0.846      0.459      0.363\n",
            "          front_bumper        208        208      0.905      0.981      0.952      0.877      0.904      0.981      0.952      0.855\n",
            "            front_door        167        167      0.829      0.928       0.94      0.826      0.829       0.93       0.94       0.81\n",
            "           front_glass        214        214      0.921      0.987      0.977      0.902      0.921      0.987      0.977      0.902\n",
            "       front_left_door         15         15      0.539          1      0.597      0.534      0.536          1      0.597      0.464\n",
            "      front_left_light         30         30      0.509        0.6      0.527      0.387      0.531      0.641      0.556      0.386\n",
            "           front_light        248        373      0.861      0.879      0.885      0.674      0.866      0.886      0.891      0.648\n",
            "      front_right_door         12         12      0.374      0.833      0.565      0.486       0.37      0.833      0.565      0.412\n",
            "     front_right_light         26         26      0.518      0.808      0.696      0.539      0.514      0.808      0.696      0.523\n",
            "                  hood        214        214      0.908      0.967      0.937      0.831      0.907      0.967      0.936      0.829\n",
            "           left_mirror         31         31      0.449      0.605      0.431      0.296       0.45      0.613      0.431      0.252\n",
            "                object          1          1          0          0          0          0          0          0          0          0\n",
            "          right_mirror         31         31      0.516      0.756       0.64      0.418      0.518      0.762       0.64       0.41\n",
            "              tailgate          5          5      0.337        0.8      0.541       0.41      0.335        0.8      0.605      0.449\n",
            "                 trunk          9          9      0.339      0.854      0.636       0.51        0.3      0.762      0.587      0.421\n",
            "                 wheel         34         53       0.39      0.434      0.416      0.297      0.477      0.547      0.612      0.273\n",
            "Speed: 1.1ms preprocess, 5.1ms inference, 0.0ms loss, 5.7ms postprocess per image\n",
            "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Dataset sample image](https://github.com/ultralytics/docs/releases/download/0/dataset-sample-image.avif)"
      ],
      "metadata": {
        "id": "_Hapx6WkS--T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predict\n",
        "\n",
        "YOLO11 may be used directly in the Command Line Interface (CLI) with a yolo command for a variety of tasks and modes and accepts additional arguments, i.e. imgsz=640. See a full list of available [yolo arguments](https://docs.ultralytics.com/usage/cfg/) and other details in the [YOLO11 Predict Docs](https://docs.ultralytics.com/modes/train/)."
      ],
      "metadata": {
        "id": "mKAUvDAbTEjQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "model.save(\"yolo11n-carparts.pt\")\n",
        "# Load a model\n",
        "model = YOLO(\"yolo11n-carparts.pt\")  # load a fine-tuned model\n",
        "\n",
        "# Inference using the model (img/video/stream)\n",
        "results = model.predict(\"https://github.com/ultralytics/assets/releases/download/v0.0.0/carparts-image.jpg\", save=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "nzTbeqK_TB6t",
        "outputId": "a74ba853-373c-4945-84dc-4a29d6ee74e8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/path/to/best.pt'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-a9e08ed4ac94>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Load a model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mYOLO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/path/to/best.pt\"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# load a fine-tuned model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Inference using the model (img/video/stream)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/models/yolo/model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, task, verbose)\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0;31m# Continue with default YOLO initialization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, task, verbose)\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0;31m# Delete super().training for accessing self.model.training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(self, weights, task)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuffix\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\".pt\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mckpt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattempt_load_one_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"task\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moverrides\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset_ckpt_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/nn/tasks.py\u001b[0m in \u001b[0;36mattempt_load_one_weight\u001b[0;34m(weight, device, inplace, fuse)\u001b[0m\n\u001b[1;32m   1304\u001b[0m         \u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m \u001b[0mcontaining\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1305\u001b[0m     \"\"\"\n\u001b[0;32m-> 1306\u001b[0;31m     \u001b[0mckpt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch_safe_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# load ckpt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1307\u001b[0m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mDEFAULT_CFG_DICT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mckpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train_args\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m  \u001b[0;31m# combine model and default args, preferring model args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mckpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ema\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mckpt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# FP32 model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/nn/tasks.py\u001b[0m in \u001b[0;36mtorch_safe_load\u001b[0;34m(weight, safe_only)\u001b[0m\n\u001b[1;32m   1209\u001b[0m                     \u001b[0mckpt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msafe_pickle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1210\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1211\u001b[0;31m                 \u001b[0mckpt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1213\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mModuleNotFoundError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# e.name is missing module name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/utils/patches.py\u001b[0m in \u001b[0;36mtorch_load\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"weights_only\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_torch_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1423\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1425\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1426\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1427\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    749\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    752\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"w\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/path/to/best.pt'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
        "<img align=\"left\" src=\"https://github.com/user-attachments/assets/436ded05-9203-4bb7-883b-f7a1f9a399c1\" width=\"600\">"
      ],
      "metadata": {
        "id": "lmNKY3rWWsvj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Export\n",
        "\n",
        "Export a YOLO11 model to any supported format below with the `format` argument, i.e. `format=onnx`. See [YOLO11 Export Docs](https://docs.ultralytics.com/modes/export/) for more information.\n",
        "\n",
        "- üí° ProTip: Export to [ONNX](https://docs.ultralytics.com/integrations/onnx/) or [OpenVINO](https://docs.ultralytics.com/integrations/openvino/) for up to 3x CPU speedup.  \n",
        "- üí° ProTip: Export to [TensorRT](https://docs.ultralytics.com/integrations/tensorrt/) for up to 5x GPU speedup.\n",
        "\n",
        "| Format                                                                   | `format` Argument | Model                     | Metadata | Arguments                                                            |\n",
        "|--------------------------------------------------------------------------|-------------------|---------------------------|----------|----------------------------------------------------------------------|\n",
        "| [PyTorch](https://pytorch.org/)                                          | -                 | `yolo11n.pt`              | ‚úÖ        | -                                                                    |\n",
        "| [TorchScript](https://docs.ultralytics.com/integrations/torchscript)     | `torchscript`     | `yolo11n.torchscript`     | ‚úÖ        | `imgsz`, `optimize`, `batch`                                         |\n",
        "| [ONNX](https://docs.ultralytics.com/integrations/onnx)                   | `onnx`            | `yolo11n.onnx`            | ‚úÖ        | `imgsz`, `half`, `dynamic`, `simplify`, `opset`, `batch`             |\n",
        "| [OpenVINO](https://docs.ultralytics.com/integrations/openvino)           | `openvino`        | `yolo11n_openvino_model/` | ‚úÖ        | `imgsz`, `half`, `dynamic`, `int8`, `batch`                          |\n",
        "| [TensorRT](https://docs.ultralytics.com/integrations/tensorrt)           | `engine`          | `yolo11n.engine`          | ‚úÖ        | `imgsz`, `half`, `dynamic`, `simplify`, `workspace`, `int8`, `batch` |\n",
        "| [CoreML](https://docs.ultralytics.com/integrations/coreml)               | `coreml`          | `yolo11n.mlpackage`       | ‚úÖ        | `imgsz`, `half`, `int8`, `nms`, `batch`                              |\n",
        "| [TF SavedModel](https://docs.ultralytics.com/integrations/tf-savedmodel) | `saved_model`     | `yolo11n_saved_model/`    | ‚úÖ        | `imgsz`, `keras`, `int8`, `batch`                                    |\n",
        "| [TF GraphDef](https://docs.ultralytics.com/integrations/tf-graphdef)     | `pb`              | `yolo11n.pb`              | ‚ùå        | `imgsz`, `batch`                                                     |\n",
        "| [TF Lite](https://docs.ultralytics.com/integrations/tflite)              | `tflite`          | `yolo11n.tflite`          | ‚úÖ        | `imgsz`, `half`, `int8`, `batch`                                     |\n",
        "| [TF Edge TPU](https://docs.ultralytics.com/integrations/edge-tpu)        | `edgetpu`         | `yolo11n_edgetpu.tflite`  | ‚úÖ        | `imgsz`                                                              |\n",
        "| [TF.js](https://docs.ultralytics.com/integrations/tfjs)                  | `tfjs`            | `yolo11n_web_model/`      | ‚úÖ        | `imgsz`, `half`, `int8`, `batch`                                     |\n",
        "| [PaddlePaddle](https://docs.ultralytics.com/integrations/paddlepaddle)   | `paddle`          | `yolo11n_paddle_model/`   | ‚úÖ        | `imgsz`, `batch`                                                     |\n",
        "| [MNN](https://docs.ultralytics.com/integrations/mnn)                     | `mnn`             | `yolo11n.mnn`             | ‚úÖ        | `imgsz`, `batch`, `int8`, `half`                                     |\n",
        "| [NCNN](https://docs.ultralytics.com/integrations/ncnn)                   | `ncnn`            | `yolo11n_ncnn_model/`     | ‚úÖ        | `imgsz`, `half`, `batch`                                             |\n",
        "| [IMX500](https://docs.ultralytics.com/integrations/sony-imx500)          | `imx`             | `yolov8n_imx_model/`      | ‚úÖ        | `imgsz`, `int8`                                                      |\n",
        "| [RKNN](https://docs.ultralytics.com/integrations/rockchip-rknn)          | `rknn`            | `yolo11n_rknn_model/`     | ‚úÖ        | `imgsz`, `batch`, `name`                                             |"
      ],
      "metadata": {
        "id": "vWBYYdXhTkN7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load a model\n",
        "model = YOLO(\"/path/to/best.pt\")  # load a custom trained model\n",
        "\n",
        "# Export the model\n",
        "model.export(format=\"onnx\")"
      ],
      "metadata": {
        "id": "S4nWG40CTlOD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}